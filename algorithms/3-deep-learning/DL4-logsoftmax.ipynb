{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL4 Log Softmax函数的实现\n",
    "## 描述\n",
    "实现log-softmax函数。log-softmax是softmax函数的对数形式，在深度学习中常用于提高数值计算的稳定性。\n",
    "需要在运算之前减去最大值保证数值稳定性。\n",
    "\n",
    "## 输入描述：\n",
    "输入一个列表，列表中的元素为浮点数。\n",
    "\n",
    "## 输出描述：\n",
    "输出一个numpy数组，代表log-softmax的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_softmax(scores: list) -> np.ndarray:\n",
    "    socres = np.array(scores)-np.max(scores)\n",
    "    return scores - np.log(np.sum(np.exp(scores)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scores = eval(input())\n",
    "    print(log_softmax(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Softmax函数（Log Softmax）是一种常用的激活函数，是Softmax函数的对数形式，其计算公式为：\n",
    "\n",
    "$$\n",
    "f(x) = \\log\\left(\\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}}\\right)\n",
    "$$\n",
    "\n",
    "其中，$x$是输入。该算法是深度学习中常用的激活函数之一。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
