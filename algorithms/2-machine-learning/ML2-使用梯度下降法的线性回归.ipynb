{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML2 使用梯度下降的线性回归\n",
    "[牛客网](https://www.nowcoder.com/practice/e9f12bb403f44847b44e287d5a71e56c?tpId=379&tqId=11118316&sourceUrl=%2Fexam%2Foj%3Fpage%3D1%26tab%3DAI%25E7%25AF%2587%26topicId%3D379)\n",
    "\n",
    "## 描述\n",
    "编写一个使用梯度下降执行线性回归的 Python 函数。该函数应将 NumPy 数组 X（具有一列截距的特征）和 y（目标）作为输入，以及学习率 alpha 和迭代次数，并返回一个 NumPy 数组，表示线性回归模型的系数。\n",
    "## 输入描述：\n",
    "第1行输入X，第2行输入y，第3行输入alpha，第4行输入迭代次数。\n",
    "\n",
    "## 输出描述：\n",
    "输出线性回归模型的系数，四舍五入到小数点后四位。返回类型是List类型。\n",
    "\n",
    "```\n",
    "输入:\n",
    "[[1, 1], [1, 2], [1, 3], [1, 4]]\n",
    "[2, 3, 4, 5]\n",
    "0.01\n",
    "1000\n",
    "\n",
    "输出: \n",
    "[0.8678 1.045 ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8678 1.045 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def linear_regression_gradient_descent(X, y, alpha, iterations):\n",
    "    # 补全代码\n",
    "    m,n = X.shape\n",
    "    theta = np.zeros((n,1)) # 为了和答案一致\n",
    "    for _ in range(iterations):\n",
    "        y_predict = X@theta\n",
    "        errors = y_predict - y\n",
    "        discent = X.T@(errors)/m\n",
    "        theta = theta - alpha * discent\n",
    "    return np.round(theta.flatten(), 4)\n",
    "\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入矩阵和向量\n",
    "    matrix_inputx = input()\n",
    "    array_y = input()\n",
    "    alpha = input()\n",
    "    iterations = input()\n",
    "\n",
    "    # 处理输入\n",
    "    import ast\n",
    "    matrix = np.array(ast.literal_eval(matrix_inputx))\n",
    "    y = np.array(ast.literal_eval(array_y)).reshape(-1,1)\n",
    "    alpha = float(alpha)\n",
    "    iterations = int(iterations)\n",
    "\n",
    "    # 调用函数计算逆矩阵\n",
    "    output = linear_regression_gradient_descent(matrix,y,alpha,iterations)\n",
    "    \n",
    "    # 输出结果\n",
    "    print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度下降求解\n",
    "\n",
    "梯度下降是一种计算局部最小值的一种方法。梯度下降思想就是给定一个初始值𝜃，每次沿着函数梯度下降的方向移动𝜃：\n",
    "\n",
    "$$\n",
    "\\theta^{(t+1)} := \\theta^{(t)} - \\alpha \\nabla_{\\theta} J(\\theta^{(t)})\n",
    "$$\n",
    "\n",
    "\n",
    "在梯度为零或趋近于零的时候收敛\n",
    "$$\n",
    "J(\\theta)=\\frac{1}{2n}\\sum^n_{i=1}(x_i^T\\theta-y_i)^2\n",
    "$$\n",
    "对损失函数求偏导可得到 (n个样本，每个样本p维)\n",
    "$$\n",
    "x_i=(x_{i,0},...,x_{i,p})^T\\\\\n",
    "x_{ij}表示第i个样本的第j个分量\\\\\n",
    "\\frac{\\partial}{\\theta_j}\\frac{1}{2n}(x_i^T\\theta-y_i)^2=\\frac{\\partial}{\\theta_j}\\frac{1}{2n}(\\sum^p_{j=0}x_{i,j}\\theta_j-y_i)^2=\\frac{1}{n}(\\sum^p_{j=0}x_{i,j}\\theta_j-y_i)x_{i,j}=\\frac{1}{n}(f(x_i)-y_i))x_{i,j}\n",
    "\\\\\n",
    "\\nabla_\\theta J=\\begin{bmatrix}\n",
    "\\frac{J}{\\theta_0}\\\\\n",
    "\\frac{J}{\\theta_1}\\\\...\\\\\n",
    "\\frac{J}{\\theta_p}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "对于只有一个训练样本的训练组而言，每走一步，𝜃𝑗(𝑗= 0,1,…,𝑝)的更新公式就可以写成：\n",
    "$$\n",
    "\\theta_j^{(t+1)} := \\theta_j^{(t)} - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta_j^{(t)}) = \\theta_j^{(t)} - \\alpha \\frac{1}{n} (f(x_i) - y_i) x_{i,j}\n",
    "$$\n",
    "因此，当有 n 个训练实例的时候（批处理梯度下降算法），该公式就可以写为：\n",
    "$$\n",
    "\\theta_j^{(t+1)}:=\\theta_j^{(t)}-\\alpha\\frac{1}{n}\\sum^n_{i=1}(f(x_i)-y_i)x_{i,j}\n",
    "$$\n",
    "这样，每次根据所有数据求出偏导，然后根据特定的步长𝛼，就可以不断更新𝜃𝑗，直到其收敛。当<mark>梯度为0或目标函数值不能继续下降的时候</mark>，就可以说已经收敛，即目标函数达到局部最小值。\n",
    "\n",
    "具体过程可以归纳如下\n",
    "\n",
    "> :one: 初始化𝜃（随机初始化）\n",
    ">\n",
    "> :two: 利用如下公式更新𝜃\n",
    "> $$\n",
    "> \\theta_j^{(t+1)}:=\\theta_j^{(t)}-\\alpha \\frac{1}{n}\\sum^n_{i=1}(f(x_i)-y_i)x_{i,j}\\\\\n",
    "> \\theta^{(t+1)}:=\\theta^{(t)}-\\alpha \\frac{1}{n}\\sum^n_{i=1}(f(x_i)-y_i)x_{i}\n",
    "> $$\n",
    "> 其中α为步长\n",
    ">\n",
    "> :three: 如果新的𝜃能使𝐽(𝜃)继续减少，继续利用上述步骤更新𝜃，否则收敛，停止迭代。\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tx-rca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
