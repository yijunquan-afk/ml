# ML1 ä½¿ç”¨æ­£è§„æ–¹ç¨‹çš„çº¿æ€§å›å½’

## æè¿°
ç¼–å†™ä¸€ä¸ªä½¿ç”¨æ­£è§„æ–¹ç¨‹æ‰§è¡Œçº¿æ€§å›å½’çš„ Python å‡½æ•°ã€‚
å‡½æ•°è¾“å…¥æ˜¯ä¸€ä¸ªçŸ©é˜µ Xï¼ˆç‰¹å¾ï¼‰å’Œå‘é‡ yï¼ˆç›®æ ‡ï¼‰ï¼Œè¿”å›çº¿æ€§å›å½’æ¨¡å‹çš„ç³»æ•°ã€‚
æœ€åçš„ç­”æ¡ˆå››èˆäº”å…¥ä¿ç•™å°æ•°ç‚¹åå››ä½ã€‚

## è¾“å…¥æè¿°ï¼š
ç¬¬1è¡Œè¾“å…¥çŸ©é˜µ Xï¼Œç¬¬2è¡Œè¾“å…¥å‘é‡ yã€‚

## è¾“å‡ºæè¿°ï¼š
è¾“å‡ºçº¿æ€§å›å½’æ¨¡å‹çš„ç³»æ•°ã€‚å‡½æ•°è¿”å›ç±»å‹æ˜¯åˆ—è¡¨ç±»å‹ï¼Œç¬¬ä¸€ä¸ªæ˜¯æƒé‡ï¼Œç¬¬äºŒä¸ªæ˜¯åç½®ã€‚


```
è¾“å…¥: 
[[1, 1], [1, 2], [1, 3]]
[2, 2, 3]

è¾“å‡º:

[1.3333, 0.5]
```


```python
import numpy as np
def linear_regression_normal_equation(X: list[list[float]], y: list[float]) -> list[float]:
    # å®ç°ä»£ç 
    theta = (np.linalg.inv(x.T@x)@x.T@y).T.round(4).reshape(-1).tolist()
    return theta


if __name__ == "__main__":
    import ast
    x = np.array(ast.literal_eval(input()))
    y = np.array(ast.literal_eval(input())).reshape(-1, 1)

    # Perform linear regression
    coefficients = linear_regression_normal_equation(x, y)

    # Print the coefficients
    print(coefficients)

```

## æ­£è§„æ–¹ç¨‹æ³•æ±‚è§£

å°†è®­ç»ƒæ•°æ®è¡¨ç¤ºæˆçŸ©é˜µå½¢å¼
$$
\mathbf{X} = 
\begin{bmatrix}
\mathbf{x}_1^T \\
\mathbf{x}_2^T \\
\vdots \\
\mathbf{x}_n^T \\
\end{bmatrix}
=
\begin{bmatrix}
x_{1,0} & x_{1,1} & \cdots & x_{1,p} \\
x_{2,0} & x_{2,1} & \cdots & x_{2,p} \\
\vdots & \vdots & \ddots & \vdots \\
x_{n,0} & x_{n,1} & \cdots & x_{n,p} \\
\end{bmatrix}
\quad
\mathbf{Y} = 
\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n \\
\end{bmatrix}
$$

$$
\mathbf{x_1}^T=[1,x_{1,1},x_{1,2},...,x_{1,p}]
$$

æŸå¤±å‡½æ•°$J(\theta)$å¯å˜ä¸º
$$
J(\theta)=\frac{1}{2}||Y-\hat Y||^2=\frac{1}{2}||Y-X\theta||^2
$$
ä½¿ç”¨çŸ©é˜µè¡¨è¾¾å½¢å¼è½¬åŒ–æŸå¤±å‡½æ•°
$$
\begin{equation}
\begin{split}
J(\theta)&=\frac{1}{2}||Y-X\theta||^2\\
&=\frac{1}{2}(X\theta-Y)^T(X\theta-Y)\\
&=\frac{1}{2}(\theta ^TX^TX\theta-2Y^TX\theta+Y^TY)(åˆ©ç”¨äº†a^Tb=b^Taæ±‚å¯¼ç»“æœ)
\end{split}
\end{equation}
$$
æœ€å°åŒ–æŸå¤±å‡½æ•°ğ½(ğœƒ)ï¼Œå¯é€šè¿‡ä»¤æ¢¯åº¦= ğŸï¼ˆğ‘+1ç»´çš„é›¶å‘é‡ï¼‰å®ç°:

<img src="https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img4/1695721704.png" alt="image-20220317095048551" style="zoom:67%;"/>

åˆ©ç”¨å…¬å¼
$$
\frac{\partial x^TBx}{\partial x}=(B+B^T)x\\
\frac{\partial x^Ta}{\partial x}=\frac{\partial a^Tx}{\partial x}=a
$$
å¯å¾—åˆ°
$$
\nabla_\theta J(\theta)=X^TX\theta-(Y^TX)^T=X^TX\theta-X^TY=0
$$
:mag:<mark>æ­£è§„æ–¹ç¨‹ä¸ºï¼š</mark>$X^TX\theta=X^TY$ï¼Œå¾—åˆ°è§£ï¼š$\theta^*=(X^TX)^{-1}X^TY$(å‡è®¾$X^TX$å¯é€†)


